"use client";

import { useState } from "react";

const content = {
  en: {
    date: "February 16, 2026",
    label: "Policy & Security",
    title:
      "China 2025 â€” Comprehensive AI Measures and What They Mean for Security",
    lead:
      "A review of China's 2025 regulatory changes, how new labeling and disclosure obligations reshape AI services, and what recent deepfake videoâ€‘conference attacks signal for security.",
    sections: [
      {
        title: "Summary",
        paragraphs: [
          "In recent years, China has developed a set of measures focused on generative AI and â€œdeep synthesisâ€ content. In 2025, additional obligations came into force targeting transparency, labeling of AIâ€‘generated content, and registration of services that can influence public opinion. These reforms arrive amid growing abuse â€” especially incidents where attackers used deepfake video and audio to deceive employees during video conferences."
        ]
      },
      {
        title: "Regulatory baseline â€” what already existed",
        paragraphs: [
          "China's generativeâ€‘AI framework took a significant step in July 2023 with the release of the â€œInterim Measures for the Management of Generative AI Services,â€ effective August 2023. These measures introduced administrative obligations for providers â€” registration, content controls, and disclosure of model identity and safety procedures. Through 2024â€“2025, this baseline was expanded with new rules and standards."
        ]
      },
      {
        title:
          "2025: comprehensive measures focused on transparency and labeling",
        paragraphs: [
          "In 2025, Chinese agencies (led by the Cyberspace Administration of China â€” CAC) finalized and released concrete requirements for labeling AIâ€‘generated content and national technical standards. Examples include:",
          "â€¢ mandatory labeling of any content fully or partially generated by AI (text, images, audio, video), under detailed methods and standards (national standard GB 45438-2025);",
          "â€¢ registration and submission requirements for generativeâ€‘AI services that affect public opinion;",
          "â€¢ stricter rules for storage and protection of training data, plus tighter controls on personal data and crossâ€‘border transfers;",
          "â€¢ obligations to implement complaint mechanisms and oversight of harmful content, with inspection and sanctions by regulators.",
          "These measures are part of a broader strategy: manage risks from largeâ€‘scale use of generative AI while encouraging domestic development under state oversight and legal frameworks."
        ]
      },
      {
        title: "Technical and operational requirements for providers",
        paragraphs: [
          "The new standards impose not only legal obligations but practical engineering requirements:",
          "â€¢ viewability: tools must clearly and persistently declare when content is AIâ€‘generated or modified;",
          "â€¢ traceability: systems must retain logs, versions, and metadata about sources and model parameters used to generate content;",
          "â€¢ preâ€‘deployment testing: public models must pass safety checks, including scenarios of misuse;",
          "â€¢ incident reporting: mandatory reporting of significant incidents and procedures to remove harmful content."
        ]
      },
      {
        title:
          "Deepfake videoâ€‘conference attacks â€” why they matter",
        paragraphs: [
          "In the business world, major attacks have already used deepfake technologies (voice clones and synthetic video) to impersonate executives and persuade employees on video calls to make transfers or disclose sensitive information. These cases show how quickly generative techniques move from â€œsynthesisâ€ to real security threats. Earlier incidents include highâ€‘profile frauds in Europe and the UK where fake audio/video resulted in millionâ€‘dollar losses.",
          "In the China context, the potential for mass dissemination of fabricated content in business or public channels makes labeling and traceability critical tools to identify and reconstruct attack sources."
        ]
      },
      {
        title:
          "What it means for AI providers and for HRI/robotics",
        paragraphs: [
          "For companies developing AI solutions (including robotics), the message is straightforward: regulatory obligations are now part of technical and business risk. Providers and integrators must:",
          "â€¢ implement mandatory labeling and user disclosures;",
          "â€¢ keep detailed records of training data and model parameters;",
          "â€¢ build mechanisms for rapid response and removal of harmful content;",
          "â€¢ develop security protocols that prevent generative agents from autonomously initiating external communications without supervision.",
          "Especially in HRI and robotic systems â€” where synthetic voice/visual outputs can be used in interactions with users or operators â€” labeling and control become an added safety layer."
        ]
      },
      {
        title: "How to prepare â€” practical steps",
        paragraphs: [
          "Recommended operational steps that FUA Robotics (and others) can implement:",
          "â€¢ add automatic labeling of generated content in UI/UX (text banners, audio tags, metadata);",
          "â€¢ run internal redâ€‘team exercises for deepfake and socialâ€‘engineering scenarios;",
          "â€¢ ensure audit logs for models and data lineage (who, when, with which prompt/parameters);",
          "â€¢ include incident response plans and regulator notification mechanisms for serious events."
        ]
      },
      {
        title: "Conclusion",
        paragraphs: [
          "China's 2025 measures establish a clear governance matrix: greater transparency, labeling obligations, and stricter operational requirements. They are a response to real threats â€” from disinformation to sophisticated videoâ€‘conference fraud. For development teams and engineers, this means security, reproducibility, and auditability are no longer â€œniceâ€‘toâ€‘haveâ€ â€” they are regulated responsibilities."
        ]
      }
    ]
  },
  hr: {
    date: "16. veljaÄe 2026.",
    label: "Policy & Security",
    title:
      "Kina 2025 â€” Sveobuhvatne mjere za umjetnu inteligenciju i rizik deepfake napada",
    lead:
      "Pregled kljuÄnih regulatornih promjena u Kini 2025., kako nove obveze oznaÄavanja i izdavanja podataka mijenjaju pejzaÅ¾ za pruÅ¾atelje AI usluga te Å¡to nam govore nedavni sluÄajevi deepfake napada kroz videoâ€‘konferencije.",
    sections: [
      {
        title: "SaÅ¾etak",
        paragraphs: [
          "Kina je u posljednim godinama razvila niz mjera usmjerenih na generativnu umjetnu inteligenciju i â€œdeep synthesisâ€ sadrÅ¾aj. U 2025. su stupile na snagu dodatne obveze koje ciljaju transparentnost, oznaÄavanje AIâ€‘generiranog sadrÅ¾aja i jasnu registraciju usluga koje mogu utjecati na javno mnijenje. Ove reforme dolaze u kontekstu sve uÄestalijih zloupotreba â€” posebno sluÄajeva u kojima su napadaÄi koristili deepfake video i audio tehnologije kako bi prevarili zaposlenike tijekom videoâ€‘konferencija."
        ]
      },
      {
        title: "Regulatorni okvir â€” Å¡to je veÄ‡ postojalo",
        paragraphs: [
          "Kineski okvir za generativnu AI zapoÄeo je znaÄajnim korakom u srpnju 2023. kada su objavljene â€œInterim Measures for the Management of Generative AI Servicesâ€ koje su stupile na snagu u kolovozu 2023. Te mjere su prve administrativne obveze posebno usmjerene prema pruÅ¾ateljima generativnih AI usluga â€” zahtijevale su registraciju, odreÄ‘ene kontrole sadrÅ¾aja i obvezu objave identiteta modela i sigurnosnih postupaka. Ove osnove su tijekom 2024.â€“2025. proÅ¡irene i dopunjene kroz nova pravila i standarde."
        ]
      },
      {
        title:
          "2025: nove, sveobuhvatne mjere fokusirane na transparentnost i oznaÄavanje",
        paragraphs: [
          "U 2025. kineske su agencije (predvoÄ‘ene Cyberspace Administration of China â€” CAC) finalizirale i objavile konkretne zahtjeve za oznaÄavanje AIâ€‘generiranog sadrÅ¾aja i nacionalne tehniÄke standarde. Primjeri obveza ukljuÄuju:",
          "â€¢ obvezu oznaÄavanja svakog sadrÅ¾aja koji je u potpunosti ili djelomiÄno generirao AI (tekst, slike, audio, video), prema novim mjerama koje postavljaju detaljne metode oznaÄavanja i standarde (nacionalni standard GB 45438-2025);",
          "â€¢ obvezu registracije i podnoÅ¡enja informacija za pruÅ¾atelje usluga generativne AI koji utjeÄu na javno mnijenje;",
          "â€¢ zahtjeve za pohranu i zaÅ¡titu podataka koriÅ¡tenih za treniranje modela, te stroÅ¾e kontrole osobnih podataka i prijenosa podataka;",
          "â€¢ obveze za implementaciju mehanizama za prituÅ¾be i nadzor nad Å¡tetnim sadrÅ¾ajem, uz moguÄ‡nost inspekcije i sankcija od strane regulatora.",
          "Takve su mjere zamiÅ¡ljene kao dio Å¡ire strategije: kontrolirati rizike koji proizlaze iz masovne upotrebe generativnih AI alata dok se istovremeno potiÄe domaÄ‡i razvoj tehnologije pod drÅ¾avnim nadzorom i pravnim okvirom."
        ]
      },
      {
        title: "TehniÄki i operativni zahtjevi za pruÅ¾atelje usluga",
        paragraphs: [
          "Novi standardi ne ostavljaju samo pravne obveze â€” oni nameÄ‡u i praktiÄne, inÅ¾enjerske zahtjeve:",
          "â€¢ viewability: alati moraju jasno i trajno deklarirati kada je sadrÅ¾aj generiran ili modificiran AIâ€‘jem;",
          "â€¢ traceability: sustavi moraju zadrÅ¾avati zapisnike, verzije i metapodatke o izvorima i parametrima modela koji su generirali sadrÅ¾aj;",
          "â€¢ preâ€‘deployment testing: modeli koji Ä‡e biti javno dostupni prolaze kroz sigurnosne provjere, ukljuÄujuÄ‡i provjeru za riziÄne scenarije zlouporabe;",
          "â€¢ incident reporting: obavezno prijavljivanje veÄ‡ih incidenata, te operativne procedure za uklanjanje Å¡tetnog sadrÅ¾aja."
        ]
      },
      {
        title: "Videoâ€‘konferencijski deepfake napadi â€” zaÅ¡to su relevantni",
        paragraphs: [
          "U poslovnom svijetu veÄ‡ su zabiljeÅ¾eni veliki napadi u kojima su napadaÄi koristili deepfake tehnologije (glasovne klonove i sintetiÄki video) kako bi imitirali izvrÅ¡ne ljude i preko videoâ€‘poziva uvjerili zaposlenike da izvedu novÄane transfere ili otkriju povjerljive informacije. Ti incidenti pokazuju koliko brzo generativne tehnike mogu prijeÄ‡i iz â€œsintezeâ€ u stvarnu sigurnosnu prijetnju. Primjeri ranijih napada ukljuÄuju poznate velike prevare u Europi i Velikoj Britaniji gdje su laÅ¾ni audioâ€‘/video prikazi doveli do milijunskih financijskih gubitaka.",
          "U kontekstu Kine, upravo zbog potencijala masovne diseminacije i Å¡irenja laÅ¾nog sadrÅ¾aja unutar poslovnih ili javnih komunikacijskih kanala, obveze oznaÄavanja i traceability postaju kljuÄni instrumenti za pronalaÅ¾enje i rekonstrukciju izvora napada."
        ]
      },
      {
        title: "Å to to znaÄi za pruÅ¾atelje AI rjeÅ¡enja i za HRI/robotiku?",
        paragraphs: [
          "Za tvrtke koje razvijaju AI rjeÅ¡enja (ukljuÄujuÄ‡i one u robotici) poruka je jednostavna: regulatorne su obveze postale dio tehniÄkog i poslovnog rizika. PruÅ¾atelji modela i integratori moraju:",
          "â€¢ implementirati obavezno oznaÄavanje i korisniÄke informacije;",
          "â€¢ voditi detaljne zapise o podacima za treniranje i parametrima modela;",
          "â€¢ izgraditi mehanizme za brzu reakciju i uklanjanje Å¡tetnog sadrÅ¾aja;",
          "â€¢ razvijati sigurnosne protokole koji sprjeÄavaju da generativni agenti autonomno pokreÄ‡u vanjske komunikacijske kanale bez nadzora.",
          "Posebno u HRI i robotskim sustavima, gdje se digitalni sadrÅ¾aj i glasovne/vidne sintetske izlaze mogu koristiti u interakciji s korisnicima ili operaterima, zahtjev za oznaÄavanjem i kontrolom postaje dodatni sloj sigurnosnog dizajna."
        ]
      },
      {
        title: "Kako se pripremiti â€” praktiÄni koraci",
        paragraphs: [
          "PreporuÄeni operativni koraci koje FUA Robotics (i druge tvrtke) mogu provesti:",
          "â€¢ uvesti automatsko oznaÄavanje generiranog sadrÅ¾aja u UI/UX (tekstualni banneri, audio oznake, metapodaci);",
          "â€¢ implementirati internu â€œred teamâ€ provjeru za scenarije deepfake napada i socijalnog inÅ¾enjeringa;",
          "â€¢ osigurati auditâ€‘logove modela i podatkovne linije (tko, kada, s kojim promptom/parametrima);",
          "â€¢ obavezno ukljuÄiti plan odgovora na incidente i mehanizme obavjeÅ¡tavanja regulatora u sluÄaju ozbiljnih incidenata."
        ]
      },
      {
        title: "ZakljuÄak",
        paragraphs: [
          "Kineske mjere 2025. stvaraju jasnu upravljaÄku matricu: poveÄ‡ana transparentnost, obveze oznaÄavanja i stroÅ¾i operativni zahtjevi. One su odgovor na stvarne prijetnje â€” od dezinformacija do sofisticiranih videoâ€‘konferencijskih prijevara. Za razvojne timove i inÅ¾enjere to znaÄi da sigurnost, reproducibilnost i auditabilnost viÅ¡e nisu samo â€œlijepi dodatciâ€ â€” veÄ‡ regulirana odgovornost."
        ]
      }
    ]
  }
};

function Paragraph({ text }: { text: string }) {
  if (text.startsWith("â€¢ ")) {
    return <li>{text.slice(2)}</li>;
  }
  if (/^\d+\.\s/.test(text)) {
    return <li>{text.replace(/^\d+\.\s/, "")}</li>;
  }
  return <p>{text}</p>;
}

export default function Post() {
  const [lang, setLang] = useState<"en" | "hr">("en");
  const t = content[lang];

  return (
    <main className="bg-white text-neutral-900 min-h-screen">
      <header className="flex flex-wrap items-center justify-between gap-4 px-8 py-8">
        <div className="flex items-center gap-6">
          <a
            href="/"
            className="text-sm font-medium text-neutral-800 hover:text-neutral-600"
          >
            FUA Robotics
          </a>
          <a
            href="/blog"
            className="text-sm font-medium text-neutral-700 hover:text-neutral-500"
          >
            Blog
          </a>
        </div>
        <div className="flex gap-4">
          <button
            onClick={() => setLang("hr")}
            className={`px-4 py-2 rounded-full text-sm border transition ${
              lang === "hr" ? "bg-black text-white" : "hover:bg-gray-100"
            }`}
          >
            ğŸ‡­ğŸ‡· Hrvatski
          </button>
          <button
            onClick={() => setLang("en")}
            className={`px-4 py-2 rounded-full text-sm border transition ${
              lang === "en" ? "bg-black text-white" : "hover:bg-gray-100"
            }`}
          >
            ğŸ‡¬ğŸ‡§ English
          </button>
        </div>
      </header>

      {/* HERO */}
      <section className="border-b border-neutral-200">
        <div className="max-w-5xl mx-auto px-6 py-20">
          <p className="text-sm uppercase tracking-wide text-neutral-500 mb-2">
            {t.label}
          </p>
          <p className="text-xs uppercase tracking-[0.2em] text-neutral-400 mb-4">
            {t.date}
          </p>
          <h1 className="text-3xl md:text-4xl font-semibold mb-4">
            {t.title}
          </h1>
          <p className="text-lg text-neutral-600 max-w-3xl">
            {t.lead}
          </p>
        </div>
      </section>

      {/* ARTICLE */}
      <article className="max-w-3xl mx-auto px-6 py-12 space-y-8 leading-relaxed text-[17px]">
        {t.sections.map((section) => {
          const bullets = section.paragraphs.filter((p) => p.startsWith("â€¢ "));
          const ordered = section.paragraphs.filter((p) => /^\d+\.\s/.test(p));
          const normal = section.paragraphs.filter(
            (p) => !p.startsWith("â€¢ ") && !/^\d+\.\s/.test(p)
          );

          return (
            <section key={`${section.title}-${section.paragraphs[0]}`} className="space-y-4">
              <h2 className="text-2xl font-semibold">{section.title}</h2>

              {normal.map((text) => (
                <Paragraph key={text} text={text} />
              ))}

              {bullets.length ? (
                <ul className="list-disc pl-6 space-y-2">
                  {bullets.map((text) => (
                    <Paragraph key={text} text={text} />
                  ))}
                </ul>
              ) : null}

              {ordered.length ? (
                <ol className="list-decimal pl-6 space-y-2">
                  {ordered.map((text) => (
                    <Paragraph key={text} text={text} />
                  ))}
                </ol>
              ) : null}
            </section>
          );
        })}
      </article>


    </main>
  );
}
